{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54cff63f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anne-\\anaconda3\\envs\\introML\\Lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] Den angitte prosedyren ble ikke funnet'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split, Subset\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d365c86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Stats: 100%|██████████| 17/17 [00:03<00:00,  5.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Train Size: 1048\n",
      "Final Validation Size: 131\n",
      "final test size: 131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# PREPROCESSING\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch_generator1 = torch.Generator().manual_seed(42)\n",
    "torch_generator2 = torch.Generator().manual_seed(43)\n",
    "\n",
    "# 1. Load the Dataset (midlertidig, for split + mean/std)\n",
    "\n",
    "temp_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(256),\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "data_dir = '../data/vehicle-type-detection'  # Assuming you run the script from the parent directory\n",
    "full_dataset_temp = datasets.ImageFolder(data_dir, transform=temp_transform)\n",
    "\n",
    "# 2. Split the Data (brukes kun til å finne indekser)\n",
    "\n",
    "train_size = int(0.8 * len(full_dataset_temp))\n",
    "val_size = len(full_dataset_temp) - train_size\n",
    "train_dataset_temp, val_dataset_temp = random_split(\n",
    "    full_dataset_temp,\n",
    "    [train_size, val_size],\n",
    "    generator=torch_generator1\n",
    ")\n",
    "\n",
    "# 3. Calculate Mean and STD on train data\n",
    "\n",
    "TEMP_BATCH_SIZE = 64\n",
    "temp_train_loader = DataLoader(train_dataset_temp, batch_size=TEMP_BATCH_SIZE, shuffle=False)\n",
    "\n",
    "def calculate_mean_and_std(loader):\n",
    "    \"\"\"Calculates channel-wise mean and standard deviation from a DataLoader.\"\"\"\n",
    "    channels_sum, channels_sq_sum, num_batches = 0, 0, 0\n",
    "\n",
    "    # Iterate over the dataset and accumulate sums\n",
    "    for data, _ in tqdm(loader, desc=\"Calculating Stats\"):\n",
    "        # data shape is (batch_size, channels, height, width)\n",
    "        channels_sum += torch.mean(data, dim=[0, 2, 3])\n",
    "        channels_sq_sum += torch.mean(data**2, dim=[0, 2, 3])\n",
    "        num_batches += 1\n",
    "\n",
    "    # Final calculation\n",
    "    mean = channels_sum / num_batches\n",
    "    # E[(X - mu)^2] = E[X^2] - (E[X])^2\n",
    "    std = torch.sqrt(channels_sq_sum / num_batches - mean**2)\n",
    "\n",
    "    # Convert tensors to lists/tuples of floats for use in transforms.Normalize\n",
    "    return mean.tolist(), std.tolist()\n",
    "\n",
    "MEAN, STD = calculate_mean_and_std(temp_train_loader)\n",
    "\n",
    "# 4. Define Preprocessing Pipelines\n",
    "\n",
    "# --> TRAIN: med random augmentering\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224, scale=(0.6, 1.0)),     # Crop to 224x224\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomAffine(degrees=15, translate=(0.1, 0.1), shear=10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=MEAN, std=STD),\n",
    "])\n",
    "\n",
    "# --> VAL/TEST: ingen random, kun deterministisk resize + normalize\n",
    "eval_transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=MEAN, std=STD),\n",
    "])\n",
    "\n",
    "# Lag to \"full-datasets\" med ulike transforms\n",
    "full_dataset_train = datasets.ImageFolder(data_dir, transform=train_transform)\n",
    "full_dataset_eval  = datasets.ImageFolder(data_dir, transform=eval_transform)\n",
    "\n",
    "# Retain the original indices from the first random_split\n",
    "train_indices = train_dataset_temp.indices\n",
    "val_indices   = val_dataset_temp.indices\n",
    "\n",
    "# Create the final, fully transformed train and validation/test datasets\n",
    "train_dataset   = Subset(full_dataset_train, train_indices)\n",
    "val_test_dataset = Subset(full_dataset_eval,  val_indices)\n",
    "\n",
    "# Split val_indices videre i val og test med samme generator som før\n",
    "val_dataset, test_dataset = random_split(\n",
    "    val_test_dataset,\n",
    "    [val_size // 2, val_size - val_size // 2],\n",
    "    generator=torch_generator2\n",
    ")\n",
    "\n",
    "# Check sizes to ensure split is preserved\n",
    "print(f\"Final Train Size: {len(train_dataset)}\")\n",
    "print(f\"Final Validation Size: {len(val_dataset)}\")\n",
    "print(f\"final test size: {len(test_dataset)}\")\n",
    "\n",
    "# 5. Create DataLoaders\n",
    "BATCH_SIZE = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "642fb7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_1(nn.Module):\n",
    "    def __init__(self, num_classes=5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "             # in_channel = 1 since we use grey scale, out_channel corresponds to # feature maps, kernel_\n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5),\n",
    "            #nn.BatchNorm2d(6),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5),\n",
    "            #nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "\n",
    "        # calculate dimensionality of flatten_dim\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.zeros(1, 1, 224, 224)\n",
    "            out = self.features(dummy)\n",
    "            flatten_dim = out.view(1, -1).shape[1]\n",
    "\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=flatten_dim, out_features= 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=128, out_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=64, out_features=num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.classifier(self.features(x))\n",
    "    \n",
    "cnn = CNN_1()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0146da22",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = CNN_1().to(device)\n",
    "\n",
    "num_epochs = 5\n",
    "learning_rate = 0.001\n",
    "#weight_decay = 0.01\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10002bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: Training loss = 1.4844944549329353\n",
      "Epoch 2/5: Training loss = 1.266832815878319\n",
      "Epoch 3/5: Training loss = 1.1226217584176497\n",
      "Epoch 4/5: Training loss = 1.1972181164857112\n",
      "Epoch 5/5: Training loss = 1.0519796483444446\n"
     ]
    }
   ],
   "source": [
    "train_loss_list = []\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}:', end=' ')\n",
    "    train_loss = 0\n",
    "    model.train()\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_loss_list.append(train_loss / len(train_loader))\n",
    "    print(f\"Training loss = {train_loss_list[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88dcc19c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1, num_epochs + 1), train_loss_list)\n",
    "plt.xlabel(\"Number of epochs\")\n",
    "plt.ylabel(\"Training loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "490cd099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val set accuracy = 70.99 %\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # sett modellen i eval-modus\n",
    "val_correct = 0\n",
    "val_total = 0\n",
    "\n",
    "with torch.no_grad():  # ingen gradienter under evaluering\n",
    "    for images, labels in val_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)                 # shape: (batch_size, num_classes)\n",
    "        _, y_pred = torch.max(outputs, dim=1)   # predikert klasse per sample\n",
    "\n",
    "        val_total += labels.size(0)             # legg til antall bilder i batchen\n",
    "        val_correct += (y_pred == labels).sum().item()\n",
    "\n",
    "val_acc = 100 * val_correct / val_total\n",
    "print(f\"Val set accuracy = {val_acc:.2f} %\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ec40a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import itertools\n",
    "import copy\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes: int = 5,\n",
    "        conv_kernel_size: int = 3,\n",
    "        conv_stride: int = 1,\n",
    "        padding: int = 1,\n",
    "        pool_kernel_size: int = 2,\n",
    "        input_size=(1, 224, 224),\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,\n",
    "                out_channels=16,\n",
    "                kernel_size=conv_kernel_size,\n",
    "                stride=conv_stride,\n",
    "                padding=padding,\n",
    "            ),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=pool_kernel_size),\n",
    "\n",
    "            nn.Conv2d(\n",
    "                in_channels=16,\n",
    "                out_channels=32,\n",
    "                kernel_size=conv_kernel_size,\n",
    "                stride=conv_stride,\n",
    "                padding=padding,\n",
    "            ),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=pool_kernel_size),\n",
    "        )\n",
    "\n",
    "        # Finn flatten-dim automatisk\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.zeros(1, *input_size)\n",
    "            out = self.features(dummy)\n",
    "            flatten_dim = out.view(1, -1).shape[1]\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(flatten_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7370d20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    device,\n",
    "    num_epochs=5,\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-4,\n",
    "):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    best_state = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # ---- TRAIN ----\n",
    "        model.train()\n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # ---- VALIDATION ----\n",
    "        model.eval()\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(images)\n",
    "                _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (preds == labels).sum().item()\n",
    "\n",
    "        val_acc = 100 * val_correct / val_total\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_state = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    # returner beste val-accuracy og state_dict\n",
    "    return best_val_acc, best_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "15909311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing config: padding=0, conv_stride=1, conv_kernel=3, pool_kernel=2, lr=0.001, batch_size=16 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anne-\\anaconda3\\envs\\introML\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy for this config: 61.07 %\n",
      "\n",
      "=== Testing config: padding=0, conv_stride=1, conv_kernel=3, pool_kernel=2, lr=0.001, batch_size=32 ===\n",
      "Validation accuracy for this config: 62.60 %\n",
      "\n",
      "=== Testing config: padding=0, conv_stride=1, conv_kernel=3, pool_kernel=2, lr=0.0003, batch_size=16 ===\n",
      "Validation accuracy for this config: 73.28 %\n",
      "\n",
      "=== Testing config: padding=0, conv_stride=1, conv_kernel=3, pool_kernel=2, lr=0.0003, batch_size=32 ===\n",
      "Validation accuracy for this config: 74.05 %\n",
      "\n",
      "=== Testing config: padding=0, conv_stride=1, conv_kernel=3, pool_kernel=3, lr=0.001, batch_size=16 ===\n",
      "Validation accuracy for this config: 72.52 %\n",
      "\n",
      "=== Testing config: padding=0, conv_stride=1, conv_kernel=3, pool_kernel=3, lr=0.001, batch_size=32 ===\n",
      "Validation accuracy for this config: 74.05 %\n",
      "\n",
      "=== Testing config: padding=0, conv_stride=1, conv_kernel=3, pool_kernel=3, lr=0.0003, batch_size=16 ===\n",
      "Validation accuracy for this config: 72.52 %\n",
      "\n",
      "=== Testing config: padding=0, conv_stride=1, conv_kernel=3, pool_kernel=3, lr=0.0003, batch_size=32 ===\n",
      "Validation accuracy for this config: 68.70 %\n",
      "\n",
      "=== Testing config: padding=0, conv_stride=1, conv_kernel=5, pool_kernel=2, lr=0.001, batch_size=16 ===\n",
      "Validation accuracy for this config: 75.57 %\n",
      "\n",
      "=== Testing config: padding=0, conv_stride=1, conv_kernel=5, pool_kernel=2, lr=0.001, batch_size=32 ===\n",
      "Validation accuracy for this config: 70.99 %\n",
      "\n",
      "=== Testing config: padding=0, conv_stride=1, conv_kernel=5, pool_kernel=2, lr=0.0003, batch_size=16 ===\n",
      "Validation accuracy for this config: 75.57 %\n",
      "\n",
      "=== Testing config: padding=0, conv_stride=1, conv_kernel=5, pool_kernel=2, lr=0.0003, batch_size=32 ===\n",
      "Validation accuracy for this config: 70.99 %\n",
      "\n",
      "=== Testing config: padding=0, conv_stride=1, conv_kernel=5, pool_kernel=3, lr=0.001, batch_size=16 ===\n",
      "Validation accuracy for this config: 70.23 %\n",
      "\n",
      "=== Testing config: padding=0, conv_stride=1, conv_kernel=5, pool_kernel=3, lr=0.001, batch_size=32 ===\n",
      "Validation accuracy for this config: 67.94 %\n",
      "\n",
      "=== Testing config: padding=0, conv_stride=1, conv_kernel=5, pool_kernel=3, lr=0.0003, batch_size=16 ===\n",
      "Validation accuracy for this config: 74.05 %\n",
      "\n",
      "=== Testing config: padding=0, conv_stride=1, conv_kernel=5, pool_kernel=3, lr=0.0003, batch_size=32 ===\n",
      "Validation accuracy for this config: 74.81 %\n",
      "\n",
      "=== Testing config: padding=0, conv_stride=2, conv_kernel=3, pool_kernel=2, lr=0.001, batch_size=16 ===\n",
      "Validation accuracy for this config: 77.86 %\n",
      "\n",
      "=== Testing config: padding=0, conv_stride=2, conv_kernel=3, pool_kernel=2, lr=0.001, batch_size=32 ===\n",
      "Validation accuracy for this config: 74.81 %\n",
      "\n",
      "=== Testing config: padding=0, conv_stride=2, conv_kernel=3, pool_kernel=2, lr=0.0003, batch_size=16 ===\n",
      "Validation accuracy for this config: 74.81 %\n",
      "\n",
      "=== Testing config: padding=0, conv_stride=2, conv_kernel=3, pool_kernel=2, lr=0.0003, batch_size=32 ===\n",
      "Validation accuracy for this config: 77.86 %\n",
      "\n",
      "=== Testing config: padding=0, conv_stride=2, conv_kernel=3, pool_kernel=3, lr=0.001, batch_size=16 ===\n",
      "Validation accuracy for this config: 74.05 %\n",
      "\n",
      "=== Testing config: padding=0, conv_stride=2, conv_kernel=3, pool_kernel=3, lr=0.001, batch_size=32 ===\n",
      "Validation accuracy for this config: 72.52 %\n",
      "\n",
      "=== Testing config: padding=0, conv_stride=2, conv_kernel=3, pool_kernel=3, lr=0.0003, batch_size=16 ===\n",
      "Validation accuracy for this config: 74.05 %\n",
      "\n",
      "=== Testing config: padding=0, conv_stride=2, conv_kernel=3, pool_kernel=3, lr=0.0003, batch_size=32 ===\n",
      "Validation accuracy for this config: 70.23 %\n",
      "\n",
      "=== Testing config: padding=0, conv_stride=2, conv_kernel=5, pool_kernel=2, lr=0.001, batch_size=16 ===\n",
      "Validation accuracy for this config: 80.92 %\n",
      "\n",
      "=== Testing config: padding=0, conv_stride=2, conv_kernel=5, pool_kernel=2, lr=0.001, batch_size=32 ===\n",
      "Validation accuracy for this config: 74.05 %\n",
      "\n",
      "=== Testing config: padding=0, conv_stride=2, conv_kernel=5, pool_kernel=2, lr=0.0003, batch_size=16 ===\n",
      "Validation accuracy for this config: 77.10 %\n",
      "\n",
      "=== Testing config: padding=0, conv_stride=2, conv_kernel=5, pool_kernel=2, lr=0.0003, batch_size=32 ===\n",
      "Validation accuracy for this config: 74.05 %\n",
      "\n",
      "=== Testing config: padding=0, conv_stride=2, conv_kernel=5, pool_kernel=3, lr=0.001, batch_size=16 ===\n",
      "Validation accuracy for this config: 77.10 %\n",
      "\n",
      "=== Testing config: padding=0, conv_stride=2, conv_kernel=5, pool_kernel=3, lr=0.001, batch_size=32 ===\n",
      "Validation accuracy for this config: 77.10 %\n",
      "\n",
      "=== Testing config: padding=0, conv_stride=2, conv_kernel=5, pool_kernel=3, lr=0.0003, batch_size=16 ===\n",
      "Validation accuracy for this config: 76.34 %\n",
      "\n",
      "=== Testing config: padding=0, conv_stride=2, conv_kernel=5, pool_kernel=3, lr=0.0003, batch_size=32 ===\n",
      "Validation accuracy for this config: 67.94 %\n",
      "\n",
      "=== Testing config: padding=1, conv_stride=1, conv_kernel=3, pool_kernel=2, lr=0.001, batch_size=16 ===\n",
      "Validation accuracy for this config: 74.05 %\n",
      "\n",
      "=== Testing config: padding=1, conv_stride=1, conv_kernel=3, pool_kernel=2, lr=0.001, batch_size=32 ===\n",
      "Validation accuracy for this config: 74.05 %\n",
      "\n",
      "=== Testing config: padding=1, conv_stride=1, conv_kernel=3, pool_kernel=2, lr=0.0003, batch_size=16 ===\n",
      "Validation accuracy for this config: 77.10 %\n",
      "\n",
      "=== Testing config: padding=1, conv_stride=1, conv_kernel=3, pool_kernel=2, lr=0.0003, batch_size=32 ===\n",
      "Validation accuracy for this config: 70.23 %\n",
      "\n",
      "=== Testing config: padding=1, conv_stride=1, conv_kernel=3, pool_kernel=3, lr=0.001, batch_size=16 ===\n",
      "Validation accuracy for this config: 77.10 %\n",
      "\n",
      "=== Testing config: padding=1, conv_stride=1, conv_kernel=3, pool_kernel=3, lr=0.001, batch_size=32 ===\n",
      "Validation accuracy for this config: 70.99 %\n",
      "\n",
      "=== Testing config: padding=1, conv_stride=1, conv_kernel=3, pool_kernel=3, lr=0.0003, batch_size=16 ===\n",
      "Validation accuracy for this config: 75.57 %\n",
      "\n",
      "=== Testing config: padding=1, conv_stride=1, conv_kernel=3, pool_kernel=3, lr=0.0003, batch_size=32 ===\n",
      "Validation accuracy for this config: 75.57 %\n",
      "\n",
      "=== Testing config: padding=1, conv_stride=1, conv_kernel=5, pool_kernel=2, lr=0.001, batch_size=16 ===\n",
      "Validation accuracy for this config: 70.99 %\n",
      "\n",
      "=== Testing config: padding=1, conv_stride=1, conv_kernel=5, pool_kernel=2, lr=0.001, batch_size=32 ===\n",
      "Validation accuracy for this config: 61.07 %\n",
      "\n",
      "=== Testing config: padding=1, conv_stride=1, conv_kernel=5, pool_kernel=2, lr=0.0003, batch_size=16 ===\n",
      "Validation accuracy for this config: 78.63 %\n",
      "\n",
      "=== Testing config: padding=1, conv_stride=1, conv_kernel=5, pool_kernel=2, lr=0.0003, batch_size=32 ===\n",
      "Validation accuracy for this config: 77.86 %\n",
      "\n",
      "=== Testing config: padding=1, conv_stride=1, conv_kernel=5, pool_kernel=3, lr=0.001, batch_size=16 ===\n",
      "Validation accuracy for this config: 70.99 %\n",
      "\n",
      "=== Testing config: padding=1, conv_stride=1, conv_kernel=5, pool_kernel=3, lr=0.001, batch_size=32 ===\n",
      "Validation accuracy for this config: 72.52 %\n",
      "\n",
      "=== Testing config: padding=1, conv_stride=1, conv_kernel=5, pool_kernel=3, lr=0.0003, batch_size=16 ===\n",
      "Validation accuracy for this config: 78.63 %\n",
      "\n",
      "=== Testing config: padding=1, conv_stride=1, conv_kernel=5, pool_kernel=3, lr=0.0003, batch_size=32 ===\n",
      "Validation accuracy for this config: 75.57 %\n",
      "\n",
      "=== Testing config: padding=1, conv_stride=2, conv_kernel=3, pool_kernel=2, lr=0.001, batch_size=16 ===\n",
      "Validation accuracy for this config: 74.81 %\n",
      "\n",
      "=== Testing config: padding=1, conv_stride=2, conv_kernel=3, pool_kernel=2, lr=0.001, batch_size=32 ===\n",
      "Validation accuracy for this config: 73.28 %\n",
      "\n",
      "=== Testing config: padding=1, conv_stride=2, conv_kernel=3, pool_kernel=2, lr=0.0003, batch_size=16 ===\n",
      "Validation accuracy for this config: 77.10 %\n",
      "\n",
      "=== Testing config: padding=1, conv_stride=2, conv_kernel=3, pool_kernel=2, lr=0.0003, batch_size=32 ===\n",
      "Validation accuracy for this config: 77.10 %\n",
      "\n",
      "=== Testing config: padding=1, conv_stride=2, conv_kernel=3, pool_kernel=3, lr=0.001, batch_size=16 ===\n",
      "Validation accuracy for this config: 74.05 %\n",
      "\n",
      "=== Testing config: padding=1, conv_stride=2, conv_kernel=3, pool_kernel=3, lr=0.001, batch_size=32 ===\n",
      "Validation accuracy for this config: 76.34 %\n",
      "\n",
      "=== Testing config: padding=1, conv_stride=2, conv_kernel=3, pool_kernel=3, lr=0.0003, batch_size=16 ===\n",
      "Validation accuracy for this config: 73.28 %\n",
      "\n",
      "=== Testing config: padding=1, conv_stride=2, conv_kernel=3, pool_kernel=3, lr=0.0003, batch_size=32 ===\n",
      "Validation accuracy for this config: 70.99 %\n",
      "\n",
      "=== Testing config: padding=1, conv_stride=2, conv_kernel=5, pool_kernel=2, lr=0.001, batch_size=16 ===\n",
      "Validation accuracy for this config: 76.34 %\n",
      "\n",
      "=== Testing config: padding=1, conv_stride=2, conv_kernel=5, pool_kernel=2, lr=0.001, batch_size=32 ===\n",
      "Validation accuracy for this config: 74.81 %\n",
      "\n",
      "=== Testing config: padding=1, conv_stride=2, conv_kernel=5, pool_kernel=2, lr=0.0003, batch_size=16 ===\n",
      "Validation accuracy for this config: 75.57 %\n",
      "\n",
      "=== Testing config: padding=1, conv_stride=2, conv_kernel=5, pool_kernel=2, lr=0.0003, batch_size=32 ===\n",
      "Validation accuracy for this config: 76.34 %\n",
      "\n",
      "=== Testing config: padding=1, conv_stride=2, conv_kernel=5, pool_kernel=3, lr=0.001, batch_size=16 ===\n",
      "Validation accuracy for this config: 76.34 %\n",
      "\n",
      "=== Testing config: padding=1, conv_stride=2, conv_kernel=5, pool_kernel=3, lr=0.001, batch_size=32 ===\n",
      "Validation accuracy for this config: 79.39 %\n",
      "\n",
      "=== Testing config: padding=1, conv_stride=2, conv_kernel=5, pool_kernel=3, lr=0.0003, batch_size=16 ===\n",
      "Validation accuracy for this config: 76.34 %\n",
      "\n",
      "=== Testing config: padding=1, conv_stride=2, conv_kernel=5, pool_kernel=3, lr=0.0003, batch_size=32 ===\n",
      "Validation accuracy for this config: 76.34 %\n",
      "\n",
      "=== GRID SEARCH DONE ===\n",
      "Best val accuracy: 80.92 %\n",
      "Best config: {'padding': 0, 'conv_stride': 2, 'conv_kernel': 5, 'pool_kernel': 2, 'lr': 0.001, 'batch_size': 16}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(2, 2))\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(16, 32, kernel_size=(5, 5), stride=(2, 2))\n",
       "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=5408, out_features=128, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=128, out_features=5, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 5\n",
    "# Hyperparametere å søke over\n",
    "padding_values        = [0, 1]\n",
    "conv_stride_values    = [1, 2]           # stride kan ikke være 0\n",
    "conv_kernel_values    = [3, 5]\n",
    "pool_kernel_values    = [2, 3]\n",
    "learning_rates        = [1e-3, 3e-4]\n",
    "batch_sizes           = [16, 32]\n",
    "\n",
    "search_space = list(itertools.product(\n",
    "    padding_values,\n",
    "    conv_stride_values,\n",
    "    conv_kernel_values,\n",
    "    pool_kernel_values,\n",
    "    learning_rates,\n",
    "    batch_sizes\n",
    "))\n",
    "\n",
    "best_config = None\n",
    "best_val_acc = 0.0\n",
    "best_model_state = None\n",
    "\n",
    "input_size = (1, 224, 224)  # siden du bruker 224x224 grayscale\n",
    "num_epochs = 5               # du kan endre dette\n",
    "\n",
    "for (\n",
    "    padding,\n",
    "    conv_stride,\n",
    "    conv_kernel,\n",
    "    pool_kernel,\n",
    "    lr,\n",
    "    batch_size\n",
    ") in search_space:\n",
    "\n",
    "    print(\n",
    "        f\"\\n=== Testing config: \"\n",
    "        f\"padding={padding}, conv_stride={conv_stride}, \"\n",
    "        f\"conv_kernel={conv_kernel}, pool_kernel={pool_kernel}, \"\n",
    "        f\"lr={lr}, batch_size={batch_size} ===\"\n",
    "    )\n",
    "\n",
    "    # Ny dataloader for denne batch-size\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=2,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=2,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    # Bygg modell\n",
    "    try:\n",
    "        model = CNN(\n",
    "            num_classes=num_classes,\n",
    "            conv_kernel_size=conv_kernel,\n",
    "            conv_stride=conv_stride,\n",
    "            padding=padding,\n",
    "            pool_kernel_size=pool_kernel,\n",
    "            input_size=input_size,\n",
    "        )\n",
    "    except RuntimeError as e:\n",
    "        print(\"Config crashed (sannsynligvis pga for liten feature map):\", e)\n",
    "        continue\n",
    "\n",
    "    val_acc, state = train_one_model(\n",
    "        model,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        device,\n",
    "        num_epochs=num_epochs,\n",
    "        lr=lr,\n",
    "        weight_decay=1e-4,   # kan du også tune hvis du vil\n",
    "    )\n",
    "\n",
    "    print(f\"Validation accuracy for this config: {val_acc:.2f} %\")\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_config = {\n",
    "            \"padding\": padding,\n",
    "            \"conv_stride\": conv_stride,\n",
    "            \"conv_kernel\": conv_kernel,\n",
    "            \"pool_kernel\": pool_kernel,\n",
    "            \"lr\": lr,\n",
    "            \"batch_size\": batch_size,\n",
    "        }\n",
    "        best_model_state = state\n",
    "\n",
    "print(\"\\n=== GRID SEARCH DONE ===\")\n",
    "print(f\"Best val accuracy: {best_val_acc:.2f} %\")\n",
    "print(\"Best config:\", best_config)\n",
    "\n",
    "# Hvis du vil bruke beste modell videre:\n",
    "best_model = CNN(\n",
    "    num_classes=num_classes,\n",
    "    conv_kernel_size=best_config[\"conv_kernel\"],\n",
    "    conv_stride=best_config[\"conv_stride\"],\n",
    "    padding=best_config[\"padding\"],\n",
    "    pool_kernel_size=best_config[\"pool_kernel\"],\n",
    "    input_size=input_size,\n",
    ")\n",
    "best_model.load_state_dict(best_model_state)\n",
    "best_model.to(device)\n",
    "best_model.eval()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "introML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
