{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2be486a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "743437e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# 1. Define Preprocessing Pipeline\n",
    "# The standard preprocessing for deep learning models is scaling to [0, 1] (via ToTensor) \n",
    "# and then Z-score normalization using known means/stds (often ImageNet values for transfer learning)\n",
    "MEAN = [0.485, 0.456, 0.406]\n",
    "STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),         # Resize all images to 256x256\n",
    "    transforms.CenterCrop(224),     # Crop to 224x224 (standard input size for many CNNs)\n",
    "    transforms.ToTensor(),          # Converts image to a PyTorch Tensor and scales to [0, 1]\n",
    "    transforms.Normalize(mean=MEAN, std=STD) # Apply normalization\n",
    "])\n",
    "\n",
    "# 2. Load the Dataset\n",
    "data_dir = '../data/vehicle-type-detecion' # Assuming you run the script from the parent directory\n",
    "full_dataset = datasets.ImageFolder(data_dir, transform=transform)\n",
    "\n",
    "# 3. Split the Data\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "# 4. Create DataLoaders\n",
    "# DataLoader handles batching, shuffling, and multi-threaded loading\n",
    "BATCH_SIZE = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70c4af80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /Users/liamshepard/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44.7M/44.7M [00:04<00:00, 9.68MB/s]\n",
      "Extracting Features: 100%|██████████| 33/33 [00:15<00:00,  2.12it/s]\n",
      "Extracting Features: 100%|██████████| 9/9 [00:04<00:00,  2.23it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load a pre-trained model (e.g., ResNet-18)\n",
    "feature_extractor = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# Freeze weights (we only want the features, not to train the extractor)\n",
    "for param in feature_extractor.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Remove the final classification layer (the last layer before the output)\n",
    "# The features are the output of the AdaptiveAvgPool2d layer (512 features for ResNet-18)\n",
    "feature_extractor = nn.Sequential(*(list(feature_extractor.children())[:-1]))\n",
    "feature_extractor.eval() # Set to evaluation mode\n",
    "\n",
    "def extract_features(data_loader):\n",
    "    features_list = []\n",
    "    labels_list = []\n",
    "    \n",
    "    with torch.no_grad(): # No need to calculate gradients for feature extraction\n",
    "        for inputs, labels in tqdm(data_loader, desc=\"Extracting Features\"):\n",
    "            # Get the features (shape: [batch_size, 512, 1, 1])\n",
    "            outputs = feature_extractor(inputs)\n",
    "            \n",
    "            # Flatten the features (shape: [batch_size, 512])\n",
    "            outputs = outputs.squeeze().cpu().numpy()\n",
    "            \n",
    "            features_list.append(outputs)\n",
    "            labels_list.append(labels.cpu().numpy())\n",
    "\n",
    "    # Concatenate all batches\n",
    "    X = np.concatenate(features_list)\n",
    "    Y = np.concatenate(labels_list)\n",
    "    return X, Y\n",
    "\n",
    "# Extract features and labels for training and validation\n",
    "X_train, Y_train = extract_features(train_loader)\n",
    "X_val, Y_val = extract_features(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb754e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost Classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liamshepard/Desktop/Skole/semester5/data/DDP/IT3212-Computer-Vision/.venv/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:03:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost Validation Accuracy: 87.40%\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize and train the XGBoost Classifier\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    objective='multi:softmax', \n",
    "    num_class=len(full_dataset.classes), \n",
    "    use_label_encoder=False, \n",
    "    eval_metric='merror',\n",
    "    n_estimators=100\n",
    ")\n",
    "\n",
    "print(\"Training XGBoost Classifier...\")\n",
    "xgb_model.fit(X_train, Y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "Y_pred_xgb = xgb_model.predict(X_val)\n",
    "xgb_accuracy = accuracy_score(Y_val, Y_pred_xgb)\n",
    "\n",
    "print(f\"\\nXGBoost Validation Accuracy: {xgb_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0b13a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Load a pre-trained ResNet-18 model\n",
    "model_cnn = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "num_ftrs = model_cnn.fc.in_features # Get the number of input features for the final layer\n",
    "\n",
    "# Replace the final fully connected layer (model_cnn.fc)\n",
    "# The output size must match the number of your classes (4: hatchback, motorcycle, pickup, sedan, suv)\n",
    "# Wait, based on your directory listing, you have 5 classes: hatchback, motorcycle, pickup, sedan, suv\n",
    "num_classes = len(full_dataset.classes) # Should be 5\n",
    "model_cnn.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "# Move the model to GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_cnn = model_cnn.to(device)\n",
    "\n",
    "# Define Loss function and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model_cnn.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2dcda206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 0: 100%|██████████| 33/33 [00:41<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2149 Acc: 0.5506\n",
      "Epoch 1/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1: 100%|██████████| 33/33 [00:40<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5578 Acc: 0.8483\n",
      "Epoch 2/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|██████████| 33/33 [00:41<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3118 Acc: 0.9208\n",
      "Epoch 3/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3: 100%|██████████| 33/33 [00:41<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2020 Acc: 0.9580\n",
      "Epoch 4/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4: 100%|██████████| 33/33 [00:41<00:00,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1249 Acc: 0.9885\n",
      "\n",
      "CNN Training Complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, criterion, optimizer, num_epochs=10):\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        for inputs, labels in tqdm(train_loader, desc=f\"Training Epoch {epoch}\"):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad() # Zero the parameter gradients\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_dataset)\n",
    "        epoch_acc = running_corrects.double() / len(train_dataset)\n",
    "\n",
    "        print(f'Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "        # Validation phase (optional, but highly recommended)\n",
    "        model.eval()\n",
    "        # ... (similar loop logic for validation, without backward pass and optimizer step)\n",
    "        \n",
    "    return model\n",
    "\n",
    "# Train the CNN\n",
    "model_cnn = train_model(model_cnn, criterion, optimizer, num_epochs=5)\n",
    "print(\"\\nCNN Training Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ae622a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 9/9 [00:03<00:00,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final Validation Loss: 0.2391\n",
      "✅ Final Validation Accuracy: 93.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate_model(model, data_loader, criterion, device):\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval() \n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    # Disable gradient calculations for inference (saves memory and speeds up computation)\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(data_loader, desc=\"Validating\"):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Get predictions\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "\n",
    "            # Update statistics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            total_samples += inputs.size(0)\n",
    "\n",
    "    # Calculate final loss and accuracy\n",
    "    final_loss = running_loss / total_samples\n",
    "    final_acc = running_corrects.double() / total_samples\n",
    "    \n",
    "    return final_loss, final_acc.item()\n",
    "\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "# Assuming these variables are defined from your training setup:\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# model_cnn = ... # your trained model\n",
    "# val_loader = ... # your validation data loader\n",
    "\n",
    "final_val_loss, final_val_acc = evaluate_model(\n",
    "    model=model_cnn,\n",
    "    data_loader=val_loader,\n",
    "    criterion=criterion,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(f\"✅ Final Validation Loss: {final_val_loss:.4f}\")\n",
    "print(f\"✅ Final Validation Accuracy: {final_val_acc * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
